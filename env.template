# HDL AI Proteus Environment Configuration Template
# Copy this file to .env and fill in your configuration

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Server host (0.0.0.0 for all interfaces, localhost for local only)
SERVER_HOST=0.0.0.0

# Server port
SERVER_PORT=5000

# Debug mode (true/false) - set to false in production
SERVER_DEBUG=false

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Application name
APP_NAME=HDL AI Proteus

# Application version
APP_VERSION=1.0.0

# Environment (development, production, testing)
ENVIRONMENT=development

# Secret key for Flask sessions (generate a secure random string)
SECRET_KEY=your-secret-key-here

# Default AI provider (azure_openai, gemini, openai)
DEFAULT_PROVIDER=azure_openai

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log file path
LOG_FILE_PATH=logs/hdl_proteus.log

# =============================================================================
# COMPILER CONFIGURATION
# =============================================================================

# GHDL path (leave as 'ghdl' if in PATH)
GHDL_PATH=ghdl

# Icarus Verilog path (leave as 'iverilog' if in PATH)
IVERILOG_PATH=iverilog

# =============================================================================
# DIRECTORY CONFIGURATION
# =============================================================================

# Export directory for generated .pdsprj files
EXPORT_DIRECTORY=export

# Temporary directory for processing
TEMP_DIRECTORY=temp

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# Require API key for requests (true/false)
API_KEY_REQUIRED=false

# API key header name
API_KEY_HEADER=X-API-Key

# Enable rate limiting (true/false)
RATE_LIMITING_ENABLED=false

# Rate limit per minute
RATE_LIMIT_PER_MINUTE=60

# Maximum prompt length in characters
MAX_PROMPT_LENGTH=10000

# =============================================================================
# AI PROVIDER CONFIGURATION (Optional - can be passed in requests instead)
# =============================================================================

# Azure OpenAI Configuration
# AZURE_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_API_KEY=your-azure-openai-api-key
# AZURE_API_VERSION=2024-02-15-preview
# AZURE_DEPLOYMENT=gpt-4o

# Google Gemini Configuration
# GEMINI_API_KEY=your-gemini-api-key
# GEMINI_MODEL=gemini-1.5-pro

# OpenAI Configuration
# OPENAI_API_KEY=sk-your-openai-api-key
# OPENAI_MODEL=gpt-4

# =============================================================================
# DOCKER CONFIGURATION (for docker-compose)
# =============================================================================

# Exposed port for docker-compose
# DOCKER_PORT=5000

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================

# Enable CORS (true/false)
CORS_ENABLED=true

# CORS origins (comma-separated)
CORS_ORIGINS=*

# =============================================================================
# PRODUCTION CONFIGURATION
# =============================================================================

# Number of worker processes (for Gunicorn)
# WORKERS=4

# Worker timeout in seconds
# WORKER_TIMEOUT=300

# =============================================================================
# NOTES
# =============================================================================

# 1. Replace all placeholder values with your actual configuration
# 2. Keep this file secure and never commit it to version control
# 3. For production, set strong SECRET_KEY and appropriate security settings
# 4. You can configure AI providers here or pass them in API requests
# 5. Make sure GHDL and Icarus Verilog are installed and accessible